{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. Cells in which \"# YOUR CODE HERE\" is found are the cells where your graded code should be written.\n",
    "2. In order to test out or debug your code you may also create notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\". We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "3. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "4. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will lose points for your work in that section.\n",
    "5. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "6. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the autograder will ignore the modified \"assert\" statement. Make sure you don't edit the assert statements.\n",
    "7. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "8. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "9. The **Grading** section at the end of the document (before the **Feedback** section) contains some code for our autograder on GradeScope. You are expected to fail this block of code in your Jupyter environment. DO NOT edit this block of code, or you may not get points for your assignment.\n",
    "10. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb8ad13c2802772aebe35f0a5518f3a5",
     "grade": false,
     "grade_id": "cell-c76eacfadca2d44b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Unsupervised Learning - Clustering & Manifolds\n",
    "\n",
    "In this exercise we will look at a variety of clustering methods including manifold-based methods.\n",
    "\n",
    "First, we examine Agglomerative Clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bdbd73329473e5e4",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78cc6acb159043e8",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "449f02c7d818f70a0794600fdab4cae0",
     "grade": false,
     "grade_id": "cell-a8f841725476d32d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will be using the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d77d666d281a463",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_features = iris[\"data\"]\n",
    "iris_targets = iris[\"target\"]\n",
    "print(iris[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28bff53c0b9553ec31fd0e187de16116",
     "grade": false,
     "grade_id": "cell-da99b7ac1ee476ac",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Agglomerative Clustering\n",
    "\n",
    "In this portion of the exercise, you will plot the dendrograms when applied to the Iris dataset. To do this, you should use the [linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage) and [dendrogram](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6dc6afc58cae027c933856ba10c3a46",
     "grade": false,
     "grade_id": "cell-7ba61185fe878a6a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def dendrogram_plotter(features, methods, metric):\n",
    "    \"\"\"Plots a dendrogram for the provided features for every method in methods using the provided metric\n",
    "    \n",
    "    Args:\n",
    "        features (iterable): The features to use in creating the dendrogram\n",
    "        methods (iterable): A list of strings where each one is a valid method to the linkage function\n",
    "        metric (str): A metric for calculating the linkage\n",
    "    \"\"\"\n",
    "    for method in methods:\n",
    "        plt.figure(figsize = (10,6)) # Change the figure size to your liking\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        plt.title(f\"{method.title()} Linkage Iris Dataset Dendrogram\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "890a3424e7ef3e36e761bccd331ca851",
     "grade": true,
     "grade_id": "cell-9a3884c6587cb41a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dendrogram_plotter(iris_features, [\"average\", \"complete\", \"ward\"], \"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecfbcd423a566062785ef3704f8bf1f0",
     "grade": false,
     "grade_id": "cell-787d7939456d67c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Model Scoring\n",
    "Now we want to acquire some information about our model using features and targets. All required scores can be found in the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "208edc4cc0fa5700dbd9dea62b1ca612",
     "grade": false,
     "grade_id": "cell-1a45df2a94be8038",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def clustering_scorer(features, targets, pred):\n",
    "    \"\"\"Calculates some important clustering scores given a set of features, targets, and predictions\n",
    "    \n",
    "    Args:\n",
    "        features (iterable): The input features to the clustering problem\n",
    "        targets (iterable): The targets if this was a classification problem\n",
    "        pred (iterable): The cluster predictions for the data samples\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with the keys ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', \n",
    "            'V Score', 'Silhouette Score'] and values as the respective scores for the inputs.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4236885e5261aea19098320c0038f1f5",
     "grade": false,
     "grade_id": "cell-aa6112b880f1965c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To create agglomerative clustering estimators, use [AgglomerativeClustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering). It was already imported above. Consider using the function you just created above in developing the next function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "897eb9c6629401ce15628a2e6ce3de87",
     "grade": false,
     "grade_id": "cell-de19bff97996022b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def agg_clustering_scorer(features, targets, linkages, n_clusters=8):\n",
    "    \"\"\"Calculate the agglomerative clustering scores for a variety of linkage types\n",
    "    \n",
    "    Args:\n",
    "        features (iterable): The input features of the data\n",
    "        targets (iterable): The target classes if this was treated as a classification problem\n",
    "        linkages (iterable): A list of linkage methods to calculate scores for\n",
    "        n_clusters (int, optional): Defaults to 8. The number of clusters to use in the clustering algorithm\n",
    "    \n",
    "    Returns:\n",
    "        iterable: Scores for each linkage method similar to the clustering_scorer method's output\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for linkage in linkages:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a71411dda344157b",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "aggScores = agg_clustering_scorer(iris_features, iris_targets, [\"average\", \"complete\", \"ward\"], n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ecf525fdb70b7bef6a5a87155a2a276",
     "grade": true,
     "grade_id": "cell-8b0f9e6101ff9856",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(aggScores) == 3\n",
    "for key in ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', 'V Score', 'Silhouette Score']:\n",
    "    assert key in aggScores[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-990ec54f29e24135",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for linkage, score in zip([\"average\", \"complete\", \"ward\"],aggScores):\n",
    "    print(f\"With the {linkage} linkage,\")\n",
    "    print(f\"Adjusted rand score is {score['Adjusted Rand']}\")\n",
    "    print(f\"Adjusted mutual info score is {score['Adjusted Mutual Info']}\")\n",
    "    print(f\"Homogeneity is {score['Homogeneity']}, Completeness is {score['Completeness']}, V score is {score['V Score']}\")\n",
    "    print(f\"Silhouette score is {score['Silhouette Score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-566d434849c56af8",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "scoresdf = pd.DataFrame(aggScores, index=[\"average\", \"complete\", \"ward\"]).T # Try removing the .T and see what happens\n",
    "scoresdf.plot(kind=\"barh\")\n",
    "plt.title(\"Clustering scores with various linkage methods\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the impact of linkage criteria choice\n",
    "\n",
    "Here is a nice stack exchange discussion on what type of cluster shapes are best partitioned by a given linkage criteria. See the first response, titled \"Methods overview.\"\n",
    "https://stats.stackexchange.com/questions/195446/choosing-the-right-linkage-method-for-hierarchical-clustering\n",
    "\n",
    "- Single: \"Chain-like\" clusters\n",
    "- Complete: Clusters with compact surfaces (like a circle or sphere) but possible non-compact (dense) inside\n",
    "- Average: Generic \"close-knit collective\" clusters\n",
    "- Ward: \"Cloud\" clusters that may have outliers, as if Gaussian distributed\n",
    "\n",
    "This section demos single and complete linkage on two different types of data. Feel free to modify and explore with other data types or linkage criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "marker_size = 35\n",
    "edgecolor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll define helper functions for creating synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_circle(n, center=[0, 0], radius=1):\n",
    "    phi = np.random.rand(n)*2*np.pi\n",
    "    X = radius * np.stack((np.cos(phi), np.sin(phi)), axis=1)\n",
    "    X += np.array(center)[None, :]\n",
    "    return X\n",
    "\n",
    "def my_filled_circle(n, center=[0, 0], radius=1):\n",
    "    X = 2 * (np.random.rand(10*n, 2) - 0.5)\n",
    "    X = X[np.linalg.norm(X, axis=1) < 1, :]\n",
    "    X = radius * X[0:n, :]\n",
    "    X += np.array(center)[None, :]\n",
    "    return X\n",
    "\n",
    "def my_gaussian(n, center=[0, 0], std=1):\n",
    "    X = np.random.multivariate_normal(center, [[std, 0],[0, std]], n)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concentric circles / Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0) # Ensure repeatability\n",
    "\n",
    "n = 60 # number of points per class\n",
    "\n",
    "X = np.zeros((0, 2))\n",
    "y = np.zeros(0)\n",
    "\n",
    "centers = [[-1.25, 0], [-1.25, 0], [1.25, 0], [1.25, 0]]\n",
    "radii = [0.5, 1, 0.5, 1]\n",
    "for i, [c, r] in enumerate(zip(centers, radii)):\n",
    "    X = np.concatenate((X, my_circle(n, center=c, radius=r)))\n",
    "    y = np.concatenate((y, i * np.ones(n)))\n",
    "\n",
    "# Plot features, with and without colors to indicate class identity\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c='k', s=marker_size, edgecolor=edgecolor)\n",
    "plt.title(\"Data features\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=marker_size, edgecolor=edgecolor)\n",
    "plt.title(\"Data features with class labels\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above were intentially created to have a human-subjective hierarchy, in which the four rings could be considered four independent clusters, but one might also group the lefthand rings into a single cluster, and the righthand rings into a second cluster.\n",
    "\n",
    "Let's apply hierarchical clustering to the data, first with n_clusters=4 and then with n_cluster=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rings: n_clusters=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "\n",
    "linkages = [\"single\", \"complete\"]\n",
    "pred = []\n",
    "\n",
    "for linkage in linkages:\n",
    "    pred.append(AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage).fit_predict(X))\n",
    "\n",
    "# Plot features, with indicate cluster identity\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, linkage in enumerate(linkages):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', c=pred[i], s=marker_size, edgecolor=edgecolor)\n",
    "    plt.title(linkage)\n",
    "    plt.xlabel(\"x_1\")\n",
    "    plt.ylabel(\"x_2\")\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With n_clusters=4 we see that single linkage gave the result we would hope for. Complete linkage failed--in general, clustering points that were closer in Euclidean space rather than ones that were close to at least one other sample in the same cluster. Single linkage is a little bit like the collaborative filtering we discussed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rings: n_clusters=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "linkages = [\"single\", \"complete\"]\n",
    "pred = []\n",
    "\n",
    "for linkage in linkages:\n",
    "    pred.append(AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage).fit_predict(X))\n",
    "\n",
    "# Plot features, with indicate cluster identity\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, linkage in enumerate(linkages):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', c=pred[i], s=marker_size, edgecolor=edgecolor)\n",
    "    plt.title(linkage)\n",
    "    plt.xlabel(\"x_1\")\n",
    "    plt.ylabel(\"x_2\")\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 2 clusters, single and complete linkage both give successful results, but for different reasons.The complete linkage result is due to the Euclidean closeness of the collective points in the left cluster, and in the right cluster. The single linkage result is due to the closeness of an individual neighboring point amonst all the neighbors in the same cluster, the same reason for its success with n_clusters=4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do this again, but with a different data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0) # Ensure repeatability\n",
    "\n",
    "n = 60 # number of points per class\n",
    "\n",
    "X = np.zeros((0, 2))\n",
    "y = np.zeros(0)\n",
    "\n",
    "centers = [[-2, 1], [-2, -1], [2, 1], [2, -1]]\n",
    "stds = 0.2 * np.ones(4)\n",
    "for i, [c, s] in enumerate(zip(centers, stds)):\n",
    "    X = np.concatenate((X, my_gaussian(n, center=c, std=s)))\n",
    "    y = np.concatenate((y, i * np.ones(n)))\n",
    "\n",
    "\n",
    "# Plot features, with and without colors to indicate class identity\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c='k', s=marker_size, edgecolor=edgecolor)\n",
    "plt.title(\"Data features\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=marker_size, edgecolor=edgecolor)\n",
    "plt.title(\"Data features\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the data above were intentially created to have a human-subjective hierarchy, in which the four clouds of points could be considered four independent clusters, but one might also group the lefthand clouds into a single cluster, and the righthand clouds into a second cluster.\n",
    "\n",
    "Let's apply hierarchical clustering to the data, first with n_clusters=4 and then with n_cluster=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds: n_clusters=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "\n",
    "linkages = [\"single\", \"complete\"]\n",
    "pred = []\n",
    "\n",
    "for linkage in linkages:\n",
    "    pred.append(AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage).fit_predict(X))\n",
    "\n",
    "# Plot features, with indicate cluster identity\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, linkage in enumerate(linkages):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', c=pred[i], s=marker_size, edgecolor=edgecolor)\n",
    "    plt.title(linkage)\n",
    "    plt.xlabel(\"x_1\")\n",
    "    plt.ylabel(\"x_2\")\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the potential weakness of single linkage. Outlying points can greatly impact the results. This is directly due to the \"at least one close neighbor\" aspect of the criterion. We see that rather than clustering the samples into four cluster of nearly equal size (as was done under the complete linkage criterion), it placed almost all of the points in only the two \"higher-level\" clusters, and put only a handful of points in the remaining two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clouds: n_clusters=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "linkages = [\"single\", \"complete\"]\n",
    "pred = []\n",
    "\n",
    "for linkage in linkages:\n",
    "    pred.append(AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage).fit_predict(X))\n",
    "\n",
    "# Plot features, with indicate cluster identity\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, linkage in enumerate(linkages):\n",
    "    ax = plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', c=pred[i], s=marker_size, edgecolor=edgecolor)\n",
    "    plt.title(linkage)\n",
    "    plt.xlabel(\"x_1\")\n",
    "    plt.ylabel(\"x_2\")\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having now forced the clustering to form only two clusters, both linkage criteria do well for this data set. Where the two higher level clusters closer together, the single linkage criterion may have once again placed nearly all points into one cluster, and just one or a few points into the second cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f8a936fe40a9e1c88976335592ad2ad",
     "grade": false,
     "grade_id": "cell-9d0b21e5532456ba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f4a00fcb17652df6",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae58383ea92f9e61ecd253052ae5eb75",
     "grade": false,
     "grade_id": "cell-fa37244cf09f0bae",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a spectral clustering classifier saved as `clf`, using n_clusters=3.\n",
    "# Fit clf to the iris data\n",
    "# Predict values for the iris data using clf and save them as spectral_pred\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d36a3c20575bf99b",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spectral_scores = clustering_scorer(iris_features, iris_targets, spectral_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b52b91f47ad3cbd4a1565d9b97ecd1d8",
     "grade": true,
     "grade_id": "cell-35596289ee109dc3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for key in ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', 'V Score', 'Silhouette Score']:\n",
    "    assert key in spectral_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "714b0708360aac858f08dee8322c299e",
     "grade": true,
     "grade_id": "cell-7144bc9fd9bb85a4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert clf.n_clusters == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83ecaca7fdb1cf82",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if len(aggScores) == 3:\n",
    "    aggScores.append(spectral_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0cd3f8243e8a816",
     "locked": false,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "scoresdf = pd.DataFrame(aggScores, index=[\"average\", \"complete\", \"ward\", \"spectral\"]) # Try removing the .T and see what happens\n",
    "scoresdf.plot(kind=\"barh\")\n",
    "plt.title(\"Clustering scores with various linkage methods and Spectral Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Overview\n",
    "\n",
    "The below code is copied from http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html and is here for you to see how different methods work with varying input data. We haven't gone over all these methods and so you can focus only on what we've covered. We will go over some of the other methods in a later lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# ============\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "# ============\n",
    "n_samples = 1500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
    "                                      noise=.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "# Anisotropicly distributed data\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "# blobs with varied variances\n",
    "varied = datasets.make_blobs(n_samples=n_samples,\n",
    "                             cluster_std=[1.0, 2.5, 0.5],\n",
    "                             random_state=random_state)\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {'quantile': .3,\n",
    "                'eps': .3,\n",
    "                'damping': .9,\n",
    "                'preference': -200,\n",
    "                'n_neighbors': 10,\n",
    "                'n_clusters': 3}\n",
    "\n",
    "datasets = [\n",
    "    (noisy_circles, {'damping': .77, 'preference': -240,\n",
    "                     'quantile': .2, 'n_clusters': 2}),\n",
    "    (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
    "    (varied, {'eps': .18, 'n_neighbors': 2}),\n",
    "    (aniso, {'eps': .15, 'n_neighbors': 2}),\n",
    "    (blobs, {}),\n",
    "    (no_structure, {})]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters=params['n_clusters'], linkage='ward',\n",
    "        connectivity=connectivity)\n",
    "    spectral = cluster.SpectralClustering(\n",
    "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n",
    "        affinity=\"nearest_neighbors\")\n",
    "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "    affinity_propagation = cluster.AffinityPropagation(\n",
    "        damping=params['damping'], preference=params['preference'])\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\", affinity=\"cityblock\",\n",
    "        n_clusters=params['n_clusters'], connectivity=connectivity)\n",
    "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=params['n_clusters'], covariance_type='full')\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        ('MiniBatchKMeans', two_means),\n",
    "        ('AffinityPropagation', affinity_propagation),\n",
    "        ('MeanShift', ms),\n",
    "        ('SpectralClustering', spectral),\n",
    "        ('Ward', ward),\n",
    "        ('AgglomerativeClustering', average_linkage),\n",
    "        ('DBSCAN', dbscan),\n",
    "        ('Birch', birch),\n",
    "        ('GaussianMixture', gmm)\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        t0 = time.time()\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \" +\n",
    "                \"connectivity matrix is [0-9]{1,2}\" +\n",
    "                \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning)\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"Graph is not fully connected, spectral embedding\" +\n",
    "                \" may not work as expected.\",\n",
    "                category=UserWarning)\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "\n",
    "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                             '#f781bf', '#a65628', '#984ea3',\n",
    "                                             '#999999', '#e41a1c', '#dede00']),\n",
    "                                      int(max(y_pred) + 1))))\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "                 transform=plt.gca().transAxes, size=15,\n",
    "                 horizontalalignment='right')\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "The following code block is purely used for grading. If you find any error, you can ignore. DO NOT MODIFY THE CODE BLOCK BELOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograding with Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95e2b11a88404fb6cf097d62d5cd99cc",
     "grade": false,
     "grade_id": "cell-8c870868142b024c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
