{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rlVQM7JPaB-"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner.\n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvcc1SLSPaB_"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. Cells in which \"# YOUR CODE HERE\" is found are the cells where your graded code should be written.\n",
        "2. In order to test out or debug your code you may also create notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\". We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**.\n",
        "3. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "4. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will lose points for your work in that section.\n",
        "5. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "6. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the autograder will ignore the modified \"assert\" statement. Make sure you don't edit the assert statements.\n",
        "7. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "8. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
        "9. The **Grading** section at the end of the document (before the **Feedback** section) contains some code for our autograder on GradeScope. You are expected to fail this block of code in your Jupyter environment. DO NOT edit this block of code, or you may not get points for your assignment.\n",
        "10. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "47ccadb4be48caa31405858fec2162fb",
          "grade": false,
          "grade_id": "cell-8624ebbfca3f9d05",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "qrzxCxDYPaB_"
      },
      "source": [
        "# Deep Learning - Convolutional Neural Networks\n",
        "\n",
        "In this exercise we'll compare a simple fully-connected (dense) feedforward neural network with a convolutional neural network at predicting the [MNIST handwritten digits, drawn in a 28x28 pixel image](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "Note that each sample we're using is a grayscale image - that means that each sample (image) is a matrix of values whereas previously our samples had been vectors. You will need to modify the data to work with this accordingly. For example, keras' [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers expect their inputs to be vectors so whenever you're using a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer, make sure you convert its inputs to a vector, if needed. In keras, you can convert a matrix (or tensor) to a vector using the [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) layer. For more complex changes where you want to cusomize the exact shape of the values, you can use the [Reshape](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape) layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-69b5ab127f73f4ab",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "id": "M09EoXjbPaB_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10, mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2f12505f86743d95",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0qrjQzrPaB_",
        "outputId": "9aaaafa5-af31-41b0-a6f5-a2fb35025170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-43ee2cdae7268658",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyI85F68PaCA",
        "outputId": "9c8071b0-d733-4516-ff94-5339ead70592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MNIST data was loaded with 60000 training samples and 10000 testing samples.\n",
            "Each sample is a 28 x 28 pixel image.\n"
          ]
        }
      ],
      "source": [
        "s1 = x_train.shape\n",
        "s2 = x_test.shape\n",
        "print(f\"The MNIST data was loaded with {s1[0]} training samples and {s2[0]} testing samples.\")\n",
        "print(f\"Each sample is a {s1[1]} x {s1[2]} pixel image.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-5c9c291b795e1704",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HIcZHuvfPaCA",
        "outputId": "6dd95b7e-766f-444f-ff83-90f994b24185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-3993bfe1-e1f9-4259-876c-5e54b3d2ca69\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-3993bfe1-e1f9-4259-876c-5e54b3d2ca69 button').onclick = (e) => {\n",
              "        document.querySelector('#id-3993bfe1-e1f9-4259-876c-5e54b3d2ca69').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-3993bfe1-e1f9-4259-876c-5e54b3d2ca69 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Here's an example hand drawn digit's image\n",
        "example = x_train[0]\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "9juGCv92PaCA",
        "outputId": "883256c9-c994-48dd-ce3e-994449becc01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Now let's plot that matrix to better understand what's happening here...\n",
        "_ = plt.imshow(example, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymo4Xgx_PaCA",
        "outputId": "2fea744a-d4f9-46a2-abfc-e1a3fdb343ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "# In this cell, we'll print out the unique labels in the data.\n",
        "#\n",
        "# We're predicting the digit in an image and we have images of\n",
        "# all 10 ('0' to '9') digits.\n",
        "\n",
        "print(np.unique(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K12oreCsPaCB"
      },
      "source": [
        "### Convolutions\n",
        "\n",
        "Most engineers in computer scientists are familiar with convolutions. If you're not, or you need a refresher, try [this article on discrete convolutions](https://electricalacademia.com/signals-and-systems/example-of-discrete-time-graphical-convolution/). The article is on discrete *time* convolutions, but the process is the same for discrete *spatial* convolutions--which is what we are doing when we perform a 2D convolution on an image.\n",
        "\n",
        "To check your basic understanding of convolutions, implement the function below, which computes what the output image shape will be for a given convolutional kernel (filter) applied to a given input image. Recall that for a given dimension, the length of the output of a convolution is:\n",
        "\n",
        "`L_out = L_in - L_kernel + 1`\n",
        "\n",
        "where L_in is the length of the input (pixels), L_kernel is the length of the filter/kernel, and L_out is the length of the output (pixels)\n",
        "\n",
        "The equation above assumes that we haven't added any \"padding\" to the input image, e.g., pixels of value 0 that we use to extend/enlarge the input image. In Keras, you'll see that a user can specify padding as a scalar number of pixels to add __to each side of the image__. Thus,\n",
        "\n",
        "`L_in_padded = L_in + 2*padding`  \n",
        "`L_out = L_in_padded - L_kernel + 1`  \n",
        "`L_out = L_in + 2*padding - L_kernel + 1`  \n",
        "\n",
        "Finally, we may want to use a convolution in which the kernel doesn't \"slide\" along the input in single-pixel steps, but in multiple-pixel steps, of step size `stride`. You may want to diagram it out for yourself on a piece of paper (in a manner like that of the article linked above), but we effectively just need to divide the output length by the stride value (before adding the 1) to get strided output size. Because it may be fractional, the final answer is actually the floor of that previous result. This gives us...\n",
        "\n",
        "`L_out = floor( (L_in + 2*padding - L_kernel) / stride + 1 )`\n",
        "\n",
        "In the function below, you'll need to implement that equation separately for the horizontal and vertical dimensions of the image and kernel. Do not assume that either the image or the kernel are square. In Python, `int()` converts a number to an integer, executing a floor operation if the number is floating-point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "181818b1f77d0f52ace8cfea1f63a385",
          "grade": false,
          "grade_id": "cell-887e94c3f19aac00",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "21i1X2YDPaCB"
      },
      "outputs": [],
      "source": [
        "def calculate_conv_shape(X, K, padding=0, stride=1):\n",
        "    \"\"\"Calculate the shape of the output of a convolution\n",
        "\n",
        "    Args:\n",
        "        X (np.array): The input matrix\n",
        "        K (np.array): The filter matrix\n",
        "        padding (int, optional): Defaults to 0. The padding dimension\n",
        "        stride (int, optional): Defaults to 1. The stride of the convolution\n",
        "\n",
        "    Returns:\n",
        "        tuple: The shape of the convolution output, height then width\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    input_height, input_width = X.shape\n",
        "    kernel_height, kernel_width = K.shape\n",
        "\n",
        "    output_height = int((input_height + 2*padding - kernel_height) / stride + 1)\n",
        "    output_width = int((input_width + 2*padding - kernel_width) / stride + 1)\n",
        "\n",
        "    return (output_height, output_width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f77d68a4c1196592",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS5gvzDVPaCC",
        "outputId": "458e3f6f-fa21-467f-e257-987dcc0b683a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Here, we define a \"blurring\" filter/kernel, that can be applied\n",
        "# to an image to get a blurred output image.\n",
        "\n",
        "blur = np.array([\n",
        "    [0,    0.25, 0   ],\n",
        "    [0.25, 0.5,  0.25],\n",
        "    [0,    0.25, 0   ]\n",
        "])\n",
        "\n",
        "# If we pad our 28x28 example image and then convolve it\n",
        "# with the blurring kernel (with stride=1), the output\n",
        "# image should also be 28x28.\n",
        "calculate_conv_shape(example, blur, padding=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a69c868df7984fbcf05d18782858c39",
          "grade": true,
          "grade_id": "cell-8c49e7193a849321",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "lhibXrOhPaCC"
      },
      "outputs": [],
      "source": [
        "ans = calculate_conv_shape(example, blur, padding=1)\n",
        "assert isinstance(ans, tuple)\n",
        "assert isinstance(ans[0], int)\n",
        "assert isinstance(ans[1], int)\n",
        "assert ans == (28, 28)\n",
        "ans = calculate_conv_shape(example, blur, padding=0, stride=2)\n",
        "assert ans == (13, 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "926290a0f7c73ec67c02a53e2deb0fe3",
          "grade": false,
          "grade_id": "cell-25dbc77554a4c538",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "-zzeyo9xPaCC"
      },
      "source": [
        "### Try out a convolution\n",
        "\n",
        "To apply a convolution, you can use the [scipy.ndimage.convolve](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html). `scipy` has already been imported for you above.\n",
        "\n",
        "Convert `example` to floating point numbers using `example.astype(np.float)` before you execute the convolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d28950dc98905e27a1ad46219750ebec",
          "grade": false,
          "grade_id": "cell-eaf956c226dd39b7",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Yv28a97HPaCC",
        "outputId": "a0422c93-146e-4667-d652-2f41b8436dcd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-214731793aea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexample_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mblurred_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__expired_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "# Apply the blurring filter to the example and save the output to \"blurred_image\".\n",
        "#\n",
        "# Be sure to convert the example from unsigned int numbers to floating-point numbers\n",
        "# beforehand.\n",
        "\n",
        "# YOUR CODE HERE\n",
        "example_float = example.astype(np.float)\n",
        "blurred_image = scipy.ndimage.convolve(example_float, blur)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(example, cmap=\"gray\")\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(blurred_image, cmap=\"gray\")\n",
        "_ = plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbe761b38b1262f56ec7e75a94c7a54a",
          "grade": false,
          "grade_id": "cell-1051e90fd643f6ab",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "aSJgQJlrPaCC"
      },
      "outputs": [],
      "source": [
        "# Create a 3x3 filter of your choice (a matrix of numbers) and save it as \"my_filter\".\n",
        "#\n",
        "# Then apply that filter to the example and save the output image as \"filtered_image\".\n",
        "#\n",
        "# Again, be sure to convert the example from unsigned int numbers to floating-point\n",
        "# numbers beforehand.\n",
        "\n",
        "# YOUR CODE HERE\n",
        "my_filter = np.array([\n",
        "    [-1, -1, -1],\n",
        "    [-1,  8, -1],\n",
        "    [-1, -1, -1]\n",
        "])\n",
        "\n",
        "example_float = example.astype(np.float)\n",
        "filtered_image = scipy.ndimage.convolve(example_float, my_filter)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(example, cmap=\"gray\")\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(filtered_image, cmap=\"gray\")\n",
        "_ = plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee626d21f249b0cc04f73acd1bfd0192",
          "grade": true,
          "grade_id": "cell-dab2b2dd97bd278f",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "MmJmI_UrPaCC"
      },
      "outputs": [],
      "source": [
        "assert blurred_image.shape == example.shape\n",
        "assert filtered_image.shape == example.shape\n",
        "assert my_filter.shape == (3,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBKCEgM8PaCC"
      },
      "source": [
        "### Feedforward NN versus CNN\n",
        "\n",
        "Let's build two models -- a dense feed-forward NN and a convolutional NN. We'll train each on the MNIST training set, test them on the test set, and compare performance results (accuracy). Because the test data set is balanced (approximately 1000 samples of each of the 10 digits), accuracy is a reasonably good metric so we'll just use that rather than F-score, for simplicity.\n",
        "\n",
        "In an effort have an apples-to-apples comparison, we'll use the same number of layers in both networks, and nearly the same number of total model parameters.\n",
        "\n",
        "__We'll start by creating a the feedforward network--one with two hidden layers plus an output layer.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "488b3397640cdf6f029e5df580de2466",
          "grade": false,
          "grade_id": "cell-dd8d2962acc9833c",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "AFe14H_1PaCC"
      },
      "outputs": [],
      "source": [
        "# Create a list of Keras layers, calling it \"ff_layers\", and use the\n",
        "# Keras Sequential class to create a feedforward NN model, as you\n",
        "# did in Activity 5a.\n",
        "#\n",
        "# Your model should have two hidden Dense layers and an output Dense layer.\n",
        "#\n",
        "# Use the \"relu\" activation function for the hidden layers. Other point-wise\n",
        "# non-linear activation function might work fairly well, but ReLU is the\n",
        "# most common because of its computational efficiency as well as its\n",
        "# effectiveness.\n",
        "#\n",
        "# Use 25 neurons in each of the hidden layers.\n",
        "#\n",
        "# This is a classification task with 10 output classes so select the output\n",
        "# layer's activation function accordingly. Review the reading material or lecture\n",
        "# slides from the first deep learning lecture, 5a, if you don't recall\n",
        "# what it should be or why.\n",
        "#\n",
        "# Since the input data (image) is a matrix, you'll need to additional layers\n",
        "# at the beginning of your \"ff_layers\" list.\n",
        "# 1. An Input() layer, that tells the model what shape the input samples\n",
        "#    will be, (28, 28, 1).\n",
        "# 2. A Flatten layer, to convert that image/matrix into a vector, which\n",
        "#    is the what the subsequent Dense layer expects.\n",
        "#\n",
        "# Also, add a Dropout layer after each hidden Dense layer, for regularization.\n",
        "#\n",
        "# Finally, save the resulting Sequential model as \"ff_model\"\n",
        "\n",
        "# YOUR CODE HERE\n",
        "ff_layers = [\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(10, activation='softmax')\n",
        "]\n",
        "\n",
        "ff_model = Sequential(ff_layers)\n",
        "ff_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5QbRICDPaCD"
      },
      "source": [
        "Look at the output __above__, from `ff_model.summary()`, and take note of the __total number of model parameters__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8bc339ed2ed5a9e26fd2303ea6f357d",
          "grade": true,
          "grade_id": "cell-b9330f9b40580d4b",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "WN9QbKJKPaCD"
      },
      "outputs": [],
      "source": [
        "assert len(ff_layers) == 7\n",
        "target_type = [Flatten, Dense, Dropout, Dense, Dropout, Dense]\n",
        "for l, tt in zip(ff_model.layers, target_type):\n",
        "    assert isinstance(l, tt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5XLjuiPPaCD"
      },
      "source": [
        "### Evaluating your test or validation set while training\n",
        "\n",
        "In previous notebooks we passed our training data to `Model.fit`, which trained for a specified number of epochs. Then we plotted the training set loss (and/or metrics) as a function of epochs, allowing us to see the dynamics of the model's convergence toward a solution.\n",
        "\n",
        "In this notebook we'll also pass our test data to `Model.fit`. The Model object is smart. It will use only the training data for fitting, but it will also compute the loss and metric functions for the test data, at the end of each training epoch. Afterwards, we can plot the loss and metrics for both the training data and for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4RYEHvoPaCD"
      },
      "outputs": [],
      "source": [
        "## Let's train the model and plot the training loss curve\n",
        "#\n",
        "# We'll train for 20 epochs. If you change model parameters/hyperparameters above,\n",
        "# and the model's loss curve hasn't flattened (approximately) after 20 epochs, you\n",
        "# can increase the number of training epochs.\n",
        "\n",
        "ff_model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "n_epochs = 20\n",
        "history = ff_model.fit(x_train, y_train, epochs=n_epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['loss'], label='Train set')\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['val_loss'], label='Test set')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['accuracy'], label='Train set')\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['val_accuracy'], label='Test set')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "print(f\"\\nAccuracy on the final epoch of training was {100*history.history['accuracy'][-1]:0.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-045361b2e3f23134",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "id": "ug4wE8pCPaCD"
      },
      "outputs": [],
      "source": [
        "# Let's assess our FF model's performance on the test set\n",
        "ff_scores = ff_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"\\nThe fully-connected feedforward model achieves an accuracy of {ff_scores[1]*100:.2f}% on the test data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTpgn9f5PaCD"
      },
      "source": [
        "### Result from the feedforward NN\n",
        "\n",
        "__You may find that the accuracy on the test set is higher than reported for the training set! But it's really not. Let us explain...__\n",
        "\n",
        "We used dropout during training, which helps with model regularization (and generalization) but reduces performance when in use (i.e., during training). __When we use the `evaluate()` method, the dropout layers are \"turned off.\"__ Similarly, `fit` does not apply dropout to the test/validation set, only to the training set. If we were to put our training set through the trained model, without dropout (that is, by using `evaluate`) we would get accuracy scores like those of the test data, and likely a little bit higher.\n",
        "\n",
        "What's a good accuracy for our model? Is 50% good?\n",
        "\n",
        "Something to consider is that we have 10 classes - does that change your answer? What would random guessing's accuracy be?\n",
        "\n",
        "Based on your answer to the above questions, is your simple model good?\n",
        "\n",
        "__Let's see if we can do better. In the next section, we'll build a convolutional neural network. You'll need to use [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers from Keras.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee25e18eda6ad104129ee745ae1a1401",
          "grade": false,
          "grade_id": "cell-960d34277a5b576e",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "gjHw2uz-PaCD"
      },
      "outputs": [],
      "source": [
        "# Now you'll build a CNN that has the same number of layers as the\n",
        "# feedforward NN, and a comparable number of model parameters.\n",
        "#\n",
        "# The CNN's convolutional and pooling layers will steadily reduce the\n",
        "# number of neurons/outputs in the vertical and horizontal dimensions\n",
        "# while increasing the number of channels (the \"depth\" dimension).\n",
        "#\n",
        "# Your CNN model should be defined by a list of layers, called \"cnn_layers\",\n",
        "# organized as such:\n",
        "# [Input(),\n",
        "#  Conv2D(),\n",
        "#  MaxPool2D(),\n",
        "#  Conv2D(),\n",
        "#  MaxPool2D(),\n",
        "#  Flatten(),\n",
        "#  Dense()]\n",
        "#\n",
        "# Create that list such that the first and second Conv2D layers have 16 and\n",
        "# 32 channels, respectively. Use a (3, 3)-shaped convolutional kernel\n",
        "# for both Conv2D layers, along with \"same\" padding and \"relu\" activation.\n",
        "#\n",
        "# You can use the defaults for the MaxPool2D layers (pooling over a 2x2\n",
        "# area, which thus halves the width and height dimensions).\n",
        "#\n",
        "# You'll then flatten the output of the second/last pooling layer, and\n",
        "# send that to a Dense output layer of 10 neurons. Be sure to use the\n",
        "# appropriate activation function for the output layer, as you did for\n",
        "# the feedforward NN.\n",
        "#\n",
        "# Dropout doesn't provide much regularization support in CNN models, as\n",
        "# the constraints imposed by architecture itself provides that. So we\n",
        "# won't use Dropout layers in the CNN.\n",
        "\n",
        "# Create your CNN model using Sequential, and save it as \"cnn_model\".\n",
        "\n",
        "# YOUR CODE HERE\n",
        "cnn_layers = [\n",
        "    Input(shape=(28, 28, 1)),\n",
        "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "]\n",
        "\n",
        "cnn_model = Sequential(cnn_layers)\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEY0EtroPaCE"
      },
      "source": [
        "Look at the output __above__, from `cnn_model.summary()`, and take note of the __total number of model parameters__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "34fac23b1e3643b50ef90e676bb87d9c",
          "grade": true,
          "grade_id": "cell-44d2df9e1f2284ec",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "KxcK7Iw3PaCE"
      },
      "outputs": [],
      "source": [
        "assert len(cnn_layers) == 7\n",
        "target_type = [Conv2D, MaxPool2D, Conv2D, MaxPool2D, Flatten, Dense]\n",
        "for l, tt in zip(cnn_model.layers, target_type):\n",
        "    assert isinstance(l, tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21nugubRPaCE"
      },
      "outputs": [],
      "source": [
        "# Now we'll train the CNN model.\n",
        "#\n",
        "# Because the 2D architecture of the CNN constrains the model to learn patterns\n",
        "# that exist in 2D space (e.g., nearby pixels are more likely to exhibit some\n",
        "# connectedness/pattern than distant pixles) the model learns much more quickly\n",
        "# (that is, with fewer training epochs). So we'll only train for 3 epochs this time.\n",
        "# You can increase the number of epochs if you'd like.\n",
        "#\n",
        "# Also, the model expects the input samples to have a \"channel\" dimension, e.g.,\n",
        "# three channels (red/green/blue) for color images, 1 channel for grayscale images.\n",
        "# So we'll reshape our training images from (n_samples, 28, 28) to\n",
        "# (n_samples, 28, 28, 1).\n",
        "#\n",
        "# Note that we used 'sparse_categorical_crossentropy' as the loss function,\n",
        "# which is typical for classification tasks with a softmax output activation function.\n",
        "\n",
        "cnn_model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "n_epochs = 3\n",
        "history = cnn_model.fit(x_train.reshape(-1, 28, 28 ,1), y_train, epochs=n_epochs,\n",
        "                        validation_data=(x_test.reshape(-1, 28, 28 ,1), y_test))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['loss'], label='Train set')\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['val_loss'], label='Test set')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['accuracy'], label='Train set')\n",
        "plt.plot(np.arange(1, n_epochs+1), history.history['val_accuracy'], label='Test set')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "print(f\"\\nAccuracy on the final epoch of training was {100*history.history['accuracy'][-1]:0.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a6157eb6365d54be",
          "locked": false,
          "schema_version": 3,
          "solution": false
        },
        "id": "eS2q6m3yPaCE"
      },
      "outputs": [],
      "source": [
        "# Let's assess our CNN model's performance on the test set\n",
        "cnn_scores = cnn_model.evaluate(x_test.reshape(-1, 28, 28 ,1), y_test)\n",
        "\n",
        "print(f\"\\nThe CNN model achieves an accuracy of {cnn_scores[1]*100:.2f}% on the test data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3kXycj-PaCE"
      },
      "source": [
        "### Results from the CNN model\n",
        "\n",
        "If all went as planned, you saw notably higher accuracy from the CNN than from the feedforward network, __despite both networks having the same number of layers and nearly the same number of model parameters. It also converged much faster!__\n",
        "\n",
        "We didn't use dropout this time, so the \"artificial\" situation in which test set accuracy appears to be notably higher than training set accuracy should go away. However, even without dropout, the test set accuracy is often reported as being higher in *early* epochs, but this is for a different reason. The accuracy reported for a training set of a given epoch is the average of all batch accuracies *while the model was learning*, such that early batches did worse than later batches, within that epoch. The test set is not scored until after the training epoch is complete, so the model is \"better\" at that moment in time, and thus the test set accuracy score is higher.\n",
        "\n",
        "__Feel free to modify the FF and/or CNN networks__ -- increasing or decreasing number of neurons, numbers of layers, and types of activation functions. __Just be sure that your asserts/test cells pass after a fresh run of your notebook, before turning it in.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "89d58854a6fbaf631d5783b3d8c8df27",
          "grade": true,
          "grade_id": "cell-279d9d45069805b8",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SblRVS93PaCE"
      },
      "outputs": [],
      "source": [
        "assert cnn_scores[1] > 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ZAD8HVPaCE"
      },
      "source": [
        "### Play in the sandbox\n",
        "\n",
        "Below you may want to explore the outputs of the two models for a variety of individual samples (images). With each run, the output predictions for all 10 classes are plotted, so you can __compare the \"sharpness\" of the predicted class probability distribution__ (using the term \"probability distribution\" loosely) of the CNN versus the FF model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8hxHjdjPaCE"
      },
      "outputs": [],
      "source": [
        "# Change this value to test out some samples, and see what\n",
        "# them models' predictions look like.\n",
        "\n",
        "i = 373   # Pick any number from 0 to 9999\n",
        "\n",
        "new_example = x_test[i]\n",
        "ff_class_probabilities = ff_model.predict(new_example.reshape(-1, 28, 28))\n",
        "ff_class_prediction = np.argmax(ff_class_probabilities)\n",
        "\n",
        "cnn_class_probabilities = cnn_model.predict(new_example.reshape(-1, 28, 28, 1))\n",
        "cnn_class_prediction = np.argmax(cnn_class_probabilities)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(new_example, cmap=\"gray\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(ff_class_probabilities[0], '-bs', label='FF')\n",
        "plt.plot(ff_class_prediction, np.max(ff_class_probabilities[0]), 'bs', markersize=15)\n",
        "plt.plot(cnn_class_probabilities[0], '-ro', label='CNN')\n",
        "plt.plot(cnn_class_prediction, np.max(cnn_class_probabilities[0]), 'ro', markersize=15)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Probability')\n",
        "plt.legend(loc='center right')\n",
        "plt.grid(True)\n",
        "\n",
        "print(f\"Feedforward model predicts class {ff_class_prediction}.\")\n",
        "print(f\"        CNN model predicts class {cnn_class_prediction}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8NPHmIJPaCF"
      },
      "source": [
        "# Grading\n",
        "The following code block is purely used for grading. If you find any error, you can ignore. DO NOT MODIFY THE CODE BLOCK BELOW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQPHDTOFPaCF"
      },
      "outputs": [],
      "source": [
        "# Autograding with Otter Grader\n",
        "import otter\n",
        "grader = otter.Notebook()\n",
        "grader.check_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "48f97c6b49b742a0a7ebbd9fc0415266",
          "grade": false,
          "grade_id": "cell-ad05bf85bb55dc8e",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "06MCBOqUPaCF"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
          "grade": false,
          "grade_id": "feedback",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "fFw5_C6QPaCF"
      },
      "outputs": [],
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "\n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
          "grade": true,
          "grade_id": "feedback-tests",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "id": "3K8F_gQRPaCF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}